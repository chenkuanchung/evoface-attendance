import sys
import os
import cv2
import numpy as np
import yaml
from datetime import datetime
from PySide6.QtWidgets import (QApplication, QMainWindow, QWidget, QLabel, 
                             QVBoxLayout, QHBoxLayout, QListWidget, QFrame)
from PySide6.QtCore import QThread, Signal, Slot, Qt, QTimer
from PySide6.QtGui import QImage, QPixmap, QFont

# åŒ¯å…¥å°ˆæ¡ˆæ ¸å¿ƒæ¨¡çµ„
from src.core.detector import FaceDetector
from src.core.recognizer import FaceRecognizer
from src.core.database import AttendanceDB
from src.utils.voice import speak_success

class VideoThread(QThread):
    """
    å½±åƒè™•ç†åŸ·è¡Œç·’ï¼šè² è²¬æ“·å–å½±åƒä¸¦åŸ·è¡Œ FaceDetector (å«æ´»é«”åµæ¸¬)
    """
    change_pixmap_signal = Signal(np.ndarray, dict)

    def __init__(self, config):
        super().__init__()
        self.detector = FaceDetector()
        self.camera_index = config.get('system', {}).get('camera_index', 0)
        self._run_flag = True

    def run(self):
        cap = cv2.VideoCapture(self.camera_index)
        while self._run_flag:
            ret, frame = cap.read()
            if ret:
                # åŸ·è¡Œåµæ¸¬é‚è¼¯
                status, res = self.detector.process(frame)
                # å°‡å½±åƒèˆ‡åµæ¸¬çµæœå‚³å›ä¸»è¦–çª—
                self.change_pixmap_signal.emit(frame, {"status": status, "res": res})
        cap.release()

    def stop(self):
        self._run_flag = False
        self.wait()

class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        # è¼‰å…¥è¨­å®š
        with open("config.yaml", 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
            
        self.setWindowTitle(self.config['system']['app_name']) #
        self.setMinimumSize(1000, 700)

        # åˆå§‹åŒ–æ ¸å¿ƒçµ„ä»¶
        self.recognizer = FaceRecognizer()
        self.db = AttendanceDB()
        
        # ç‹€æ…‹æ§åˆ¶
        self.is_processing = False # é¿å…é‡è¤‡è¾¨è­˜åŒä¸€æ¬¡æ‰“å¡

        self.init_ui()
        
        # å•Ÿå‹•åŸ·è¡Œç·’
        self.video_thread = VideoThread(self.config)
        self.video_thread.change_pixmap_signal.connect(self.update_image)
        self.video_thread.start()

    def init_ui(self):
        """å»ºæ§‹ UI ä½ˆå±€"""
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QHBoxLayout(central_widget)

        # --- å·¦å´ï¼šå½±åƒé è¦½å€ ---
        left_layout = QVBoxLayout()
        self.video_label = QLabel("æ­£åœ¨å•Ÿå‹•æ”å½±æ©Ÿ...")
        self.video_label.setFixedSize(640, 480)
        self.video_label.setStyleSheet("background-color: black; border: 2px solid #333;")
        self.video_label.setAlignment(Qt.AlignCenter)
        left_layout.addWidget(self.video_label)

        # ç‹€æ…‹æç¤ºæ–‡å­—
        self.status_label = QLabel("è«‹æ­£å°æ”å½±æ©Ÿ")
        self.status_label.setFont(QFont("Microsoft JhengHei", 18, QFont.Bold))
        self.status_label.setAlignment(Qt.AlignCenter)
        self.status_label.setStyleSheet("color: #555;")
        left_layout.addWidget(self.status_label)
        
        main_layout.addLayout(left_layout, stretch=2)

        # --- å³å´ï¼šæ­·å²ç´€éŒ„å€ ---
        right_layout = QVBoxLayout()
        log_title = QLabel("ä»Šæ—¥æ‰“å¡æ¸…å–®") #
        log_title.setFont(QFont("Microsoft JhengHei", 12, QFont.Bold))
        right_layout.addWidget(log_title)

        self.log_list = QListWidget()
        self.log_list.setStyleSheet("background-color: #f9f9f9; border-radius: 5px;")
        right_layout.addWidget(self.log_list)
        
        main_layout.addLayout(right_layout, stretch=1)
        
        # åˆå§‹è¼‰å…¥ä»Šæ—¥ç´€éŒ„
        self.refresh_logs()

    @Slot(np.ndarray, dict)
    def update_image(self, frame, data):
        """è™•ç†æ¯å¹€å½±åƒæ›´æ–°èˆ‡è¾¨è­˜è§¸ç™¼"""
        status = data['status']
        res = data['res']
        h, w, _ = frame.shape

        if status == "SUCCESS":
            bbox = res['bbox']
            is_live = res['is_live']
            score = res['texture_score']

            # ç¹ªè£½ UI æ¡†ï¼šæ©˜è‰²ä»£è¡¨æƒæä¸­ï¼Œç¶ è‰²ä»£è¡¨æ´»é«”é€šé
            color = (0, 255, 0) if is_live else (0, 165, 255)
            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
            
    def update_image(self, frame, data):
        """è™•ç†æ¯å¹€å½±åƒæ›´æ–°èˆ‡è¾¨è­˜è§¸ç™¼"""
        status = data['status']
        res = data['res']
        h, w, _ = frame.shape

        if status == "SUCCESS":
            bbox = res['bbox']
            is_live = res['is_live']
            score = res['texture_score']

            # ç¹ªè£½ UI æ¡†ï¼šæ©˜è‰²ä»£è¡¨æƒæä¸­ï¼Œç¶ è‰²ä»£è¡¨æ´»é«”é€šé
            color = (0, 255, 0) if is_live else (0, 165, 255)
            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
            
            # --- å¦‚æœæ­£åœ¨è™•ç†çµæœï¼Œå°±ä¸è¦æ›´æ–°æ–‡å­—ï¼Œè®“ã€Œæ‰“å¡æˆåŠŸã€ç•™è‘— ---
            if not self.is_processing:
                if not is_live:
                    self.status_label.setText(f"è¾¨è­˜ä¸­... {int(score*100)}%")
                    self.status_label.setStyleSheet("color: #FFA500;")
                else:
                    self.status_label.setText("æ´»é«”æª¢æ¸¬é€šéï¼Œæ­£åœ¨æ¯”å°èº«åˆ†...")
                    self.status_label.setStyleSheet("color: #008000;")
                    
                    # è§¸ç™¼è¾¨è­˜é‚è¼¯
                    if res['face_img'] is not None:
                        self.perform_recognition(res['face_img'])

        elif status == "MULTIPLE_FACES":
            if not self.is_processing:
                self.status_label.setText("è­¦ç¤ºï¼šåµæ¸¬åˆ°å¤šäººï¼Œè«‹å–®äººæ‰“å¡")
                self.status_label.setStyleSheet("color: red;")
        else:
            if not self.is_processing:
                self.status_label.setText("ç­‰å¾…äººè‡‰å…¥é¡...")
                self.status_label.setStyleSheet("color: #555;")

        # è½‰æ›å½±åƒæ ¼å¼é¡¯ç¤ºåœ¨ QLabel
        rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        qimg = QImage(rgb_img.data, w, h, w * 3, QImage.Format_RGB888)
        self.video_label.setPixmap(QPixmap.fromImage(qimg))

    def perform_recognition(self, face_img):
        """åŸ·è¡Œèº«åˆ†æ¯”å°èˆ‡è€ƒå‹¤å„²å­˜"""
        self.is_processing = True
        
        # 1. åŸ·è¡Œ 1:N æ¯”å°
        emp_id, score, evolve, details, live_feat = self.recognizer.identify(face_img)
        print(f"ğŸ” [Debug] æ¯”å°çµæœ: ID={emp_id}, åˆ†æ•¸={score:.4f}, è©³ç´°={details}")
        
        if emp_id:
            photo_name = f"data/logs/{emp_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
            success, message = self.recognizer.process_attendance(
                emp_id, score, evolve, live_feat, photo_name, details
            )
            if success:
                self.status_label.setText(f"æ‰“å¡æˆåŠŸï¼š{emp_id}")
                self.refresh_logs()
                speak_success()# æ‰“å¡æˆåŠŸèªéŸ³
                # 2. å„²å­˜æ‰“å¡ç´€éŒ„èˆ‡è™•ç†ç‰¹å¾µæ¼”é€²
                os.makedirs("data/logs", exist_ok=True)
                cv2.imwrite(photo_name, face_img)
            else:
                # å¯èƒ½æ˜¯è§¸ç™¼äº† 5 åˆ†é˜å»æŠ–å‹•æ©Ÿåˆ¶
                self.status_label.setText(message)
        else:
            # å¦‚æœå¤±æ•—ï¼Œé¡¯ç¤ºåˆ†æ•¸è®“ä½ çŸ¥é“å·®å¤šå°‘
            msg = f"è¾¨è­˜å¤±æ•— (åˆ†æ•¸: {score:.2f})"
            self.status_label.setText(msg)
            print(f"âŒ {msg}")
        
        # 3. é‡ç½®åµæ¸¬å™¨ç‹€æ…‹ï¼Œæº–å‚™ä¸‹ä¸€æ¬¡è¾¨è­˜
        QTimer.singleShot(5000, self.reset_recognition) # 5ç§’å¾Œæ¢å¾©è¾¨è­˜åŠŸèƒ½

    def reset_recognition(self):
        """é‡ç½®ç‹€æ…‹ä¾›ä¸‹ä¸€ä½å“¡å·¥æ‰“å¡"""
        self.video_thread.detector.reset_liveness()
        self.is_processing = False

    def refresh_logs(self):
        """å¾è³‡æ–™åº«æŠ“å–æœ€æ–°ç´€éŒ„æ›´æ–° UI"""
        self.log_list.clear()
        logs = self.db.get_recent_logs(limit=15)
        for log in logs:
            self.log_list.addItem(f"[{log['time']}] {log['name']} (å¾—åˆ†: {log['score']})")

    def closeEvent(self, event):
        self.video_thread.stop()
        event.accept()

if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec())