import cv2
import mediapipe as mp
import numpy as np
import yaml
from src.utils.image_tool import ImagePreprocessor 
from src.core.liveness_engine import SilentFaceAnalyzer

class FaceDetector:
    def __init__(self, config_path="config.yaml"):
        # 1. è¼‰å…¥è¨­å®šæª”
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # 2. åˆå§‹åŒ–å½±åƒå·¥å…·èˆ‡æ´»é«”åˆ†æå™¨
        self.img_tool = ImagePreprocessor() 
        self.silent_face_analyzer = SilentFaceAnalyzer(config_path=config_path)
        
        # 3. åˆå§‹åŒ– MediaPipe Face Landmarker
        model_path = self.config['database']['model_path']
        BaseOptions = mp.tasks.BaseOptions
        FaceLandmarker = mp.tasks.vision.FaceLandmarker
        FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
        VisionRunningMode = mp.tasks.vision.RunningMode

        options = FaceLandmarkerOptions(
            base_options=BaseOptions(model_asset_path=model_path),
            running_mode=VisionRunningMode.IMAGE,
            min_face_detection_confidence=self.config['thresholds']['detection_confidence'],
            min_face_presence_confidence=self.config['thresholds']['detection_confidence'],
            min_tracking_confidence=self.config['thresholds']['tracking_confidence'],
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False
        )
        self.landmarker = FaceLandmarker.create_from_options(options)
        
        # 4. è®€å–é–€æª»å€¼èˆ‡ç‹€æ…‹æ§åˆ¶
        self.texture_threshold = self.config.get('thresholds', {}).get('texture_liveness', 0.95)
        self.is_locked = False
        self.texture_pass_count = 0 
        self.REQUIRED_PASS_FRAMES = 5

    def check_mask_status(self, landmarks, frame, actual_bbox):
            # 1. é»ä½é‡åˆåº¦åˆ¤æ–·ï¼šç¨å¾®èª¿é™é–€æª» (0.003 -> 0.0015)
            # MediaPipe åœ¨æ²’æˆ´å£ç½©ä¸”é–‰å˜´æ™‚ï¼Œlip_gap å¯èƒ½å°±å¾ˆå°
            lip_gap = abs(landmarks[13].y - landmarks[14].y)
            
            # 2. ç‰©ç†ç´‹ç†åˆ¤æ–· (æ¨™æº–å·®)ï¼š
            x1, y1, x2, y2 = actual_bbox
            # èª¿æ•´ ROIï¼šå–è‡‰éƒ¨é«˜åº¦çš„ 70% åˆ° 85% è™• (é€™å€é–“ä¸€å®šæœ‰å˜´å”‡æˆ–å£ç½©ä¸­å¿ƒ)
            roi_y1 = int(y1 + (y2 - y1) * 0.70)
            roi_y2 = int(y1 + (y2 - y1) * 0.85)
            roi = frame[roi_y1:roi_y2, x1:x2]
            
            std_val = 100.0 # é è¨­ä¸€å€‹å¤§å€¼(ä»£è¡¨éå£ç½©)
            if roi.size > 0:
                gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                _, stddev = cv2.meanStdDev(gray_roi)
                std_val = stddev[0][0]

            # === èª¿ç¯€å€ ===
            # å»ºè­°è§€å¯Ÿé€™è£¡çš„ print æ•¸å€¼
            # æ²’æˆ´å£ç½©çœŸäººé€šå¸¸ Std æœƒåœ¨ 12~25
            # æˆ´å£ç½©ï¼ˆå¹³é¢é¡è‰²ï¼‰é€šå¸¸ Std æœƒåœ¨ 2~8
            # print(f"Gap: {lip_gap:.5f} | Std: {std_val:.2f}")

            # æ”¾å¯¬åˆ¤å®šé–€æª»ï¼š
            # 1. lip_gap åªæœ‰åœ¨æ¥µåº¦é‡åˆ(0.001)æ™‚æ‰æ‡·ç–‘
            # 2. std_val é™åˆ° 10.0 (é€™ä»£è¡¨é¡è‰²éå¸¸æ­»æ¿)
            if lip_gap < 0.001 or std_val < 10.0:
                return True
            return False

    def process(self, frame):
            h, w, _ = frame.shape
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
            result = self.landmarker.detect(mp_image)
            
            if not result.face_landmarks:
                self.reset_liveness()
                return "NO_FACE", None
            
            if len(result.face_landmarks) > 1:
                self.reset_liveness()
                # å›å‚³å¤šè‡‰éŒ¯èª¤ï¼Œè®“ UI æç¤ºã€Œè«‹ç¢ºä¿ç•«é¢åªæœ‰ä¸€äººã€
                return "MULTIPLE_FACES", None
                
            points = result.face_landmarks[0]
            
            # 1. åº§æ¨™è¨ˆç®—èˆ‡è¾¨è­˜è·¯å¾‘ (ä¿æŒåŸæ¨£ï¼Œç¢ºä¿è¾¨è­˜å“è³ª)
            x_coords = [p.x * w for p in points]
            y_coords = [p.y * h for p in points]
            actual_bbox = [int(min(x_coords)), int(min(y_coords)), int(max(x_coords)), int(max(y_coords))]
            #is_masked = self.check_mask_status(points, h, w)
            is_masked = self.check_mask_status(points, frame, actual_bbox)
            #print(is_masked)
            
            landmarks_5pt = [
                [points[468].x * w, points[468].y * h], [points[473].x * w, points[473].y * h],
                [points[4].x * w, points[4].y * h], [points[61].x * w, points[61].y * h],
                [points[291].x * w, points[291].y * h]
            ]
            aligned_face = self.img_tool.align_face(frame, landmarks_5pt, is_masked=is_masked)
            recognition_face = self.img_tool.enhance_face(aligned_face)

            # 2. æ´»é«”è·¯å¾‘
            
            # 3. æ´»é«”è¨ˆæ¬¡é‚è¼¯ (é€²åº¦ç´¯åŠ åˆ¶)
            if not self.is_locked:
                # åŸ·è¡Œæ¨è«–å–å¾—åŸå§‹åˆ†æ•¸
                raw_score = self.silent_face_analyzer.predict(frame)
                
                # åˆ¤æ–·é€™ä¸€å¹€æ˜¯å¦ã€Œé€šéçœŸäººé–€æª»ã€
                if raw_score >= self.texture_threshold:
                    self.texture_pass_count += 1
                else:
                    # è‹¥æœ‰ä¸€å¹€æ²’éï¼Œé€²åº¦æ­¸é›¶ (ç¢ºä¿é€£çºŒæ€§ï¼Œå¢åŠ å®‰å…¨æ€§)
                    self.texture_pass_count = 0 
                
                # é”åˆ° 5 å¹€å¾Œé–å®š
                if self.texture_pass_count >= self.REQUIRED_PASS_FRAMES:
                    self.texture_pass_count = self.REQUIRED_PASS_FRAMES # å°é ‚
                    self.is_locked = True
            
            # 4. è¨ˆç®— UI é¡¯ç¤ºåˆ†æ•¸
            display_score = self.texture_pass_count / self.REQUIRED_PASS_FRAMES

            return "SUCCESS", {
                "bbox": actual_bbox,
                "is_live": self.is_locked,
                "texture_score": display_score, # å›å‚³ 0.0 ~ 1.0 çš„ç™¾åˆ†æ¯”é€²åº¦
                "face_img": recognition_face if self.is_locked else None 
            }

    def reset_liveness(self):
        self.is_locked = False
        self.texture_pass_count = 0

    def __del__(self):
        """é‡‹æ”¾ MediaPipe è³‡æº"""
        if hasattr(self, 'landmarker'):
            self.landmarker.close()

if __name__ == "__main__":
    # æ¸¬è©¦è…³æœ¬
    cap = cv2.VideoCapture(0)
    detector = FaceDetector()
    
    print("ğŸ¬ é–‹å§‹æ¸¬è©¦ Tasks API åµæ¸¬å™¨ (æŒ‰ 'q' é€€å‡º)...")
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        status, res = detector.process(frame)
        
        if status == "SUCCESS":
            # ç¶ æ¡†ä»£è¡¨çœŸäººé–å®šï¼Œæ©˜æ¡†ä»£è¡¨åˆ¤å®šä¸­
            color = (0, 255, 0) if res['is_live'] else (0, 165, 255)
            # ä½¿ç”¨å¯¦éš›è¨ˆç®—å‡ºçš„ BBox
            cv2.rectangle(frame, (res['bbox'][0], res['bbox'][1]), (res['bbox'][2], res['bbox'][3]), color, 2)
            
            # é¡¯ç¤ºæ´»é«”ç™¾åˆ†æ¯”
            score_text = f"Liveness: {res['texture_score']*100:.1f}%"
            cv2.putText(frame, score_text, (res['bbox'][0], res['bbox'][1]-10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        else:
            cv2.putText(frame, f"Status: {status}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            
        cv2.imshow("EvoFace Detector Test", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break
    
    cap.release()
    cv2.destroyAllWindows()