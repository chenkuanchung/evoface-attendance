import cv2
import mediapipe as mp
import numpy as np
import yaml
from src.utils.image_tool import ImagePreprocessor 
from src.core.liveness_engine import SilentFaceAnalyzer

class FaceDetector:
    def __init__(self, config_path="config.yaml"):
        # 1. è¼‰å…¥è¨­å®šæª”
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # 2. åˆå§‹åŒ–å½±åƒå·¥å…·èˆ‡æ´»é«”åˆ†æå™¨
        self.img_tool = ImagePreprocessor() 
        self.silent_face_analyzer = SilentFaceAnalyzer(config_path=config_path)
        
        # 3. åˆå§‹åŒ– MediaPipe Face Landmarker
        model_path = self.config['database']['model_path']
        BaseOptions = mp.tasks.BaseOptions
        FaceLandmarker = mp.tasks.vision.FaceLandmarker
        FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
        VisionRunningMode = mp.tasks.vision.RunningMode

        options = FaceLandmarkerOptions(
            base_options=BaseOptions(model_asset_path=model_path),
            running_mode=VisionRunningMode.IMAGE,
            min_face_detection_confidence=self.config['thresholds']['detection_confidence'],
            min_face_presence_confidence=self.config['thresholds']['detection_confidence'],
            min_tracking_confidence=self.config['thresholds']['tracking_confidence'],
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False
        )
        self.landmarker = FaceLandmarker.create_from_options(options)
        
        # 4. è®€å–é–€æª»å€¼èˆ‡ç‹€æ…‹æ§åˆ¶
        self.texture_threshold = self.config.get('thresholds', {}).get('texture_liveness', 0.95)
        self.is_locked = False
        self.texture_pass_count = 0 
        self.REQUIRED_PASS_FRAMES = 5

    def check_mask_status(self, landmarks, frame_h, frame_w):
        """
        ç°¡å–®çš„å£ç½©åˆ¤æ–·é‚è¼¯ï¼šæª¢æŸ¥é¼»å­èˆ‡ä¸­å¿ƒå€åŸŸ
        """
        # ç´¢å¼• 4 ç‚ºé¼»å°–
        nose = landmarks[4]
        if nose.y > 0.9 or nose.y < 0.1:
            return True
        return False

    def process(self, frame):
            h, w, _ = frame.shape
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
            result = self.landmarker.detect(mp_image)
            
            if not result.face_landmarks:
                self.reset_liveness()
                return "NO_FACE", None
                
            points = result.face_landmarks[0]
            
            # 1. åº§æ¨™è¨ˆç®—èˆ‡è¾¨è­˜è·¯å¾‘ (ä¿æŒåŸæ¨£ï¼Œç¢ºä¿è¾¨è­˜å“è³ª)
            x_coords = [p.x * w for p in points]
            y_coords = [p.y * h for p in points]
            actual_bbox = [int(min(x_coords)), int(min(y_coords)), int(max(x_coords)), int(max(y_coords))]
            is_masked = self.check_mask_status(points, h, w)
            
            landmarks_5pt = [
                [points[468].x * w, points[468].y * h], [points[473].x * w, points[473].y * h],
                [points[4].x * w, points[4].y * h], [points[61].x * w, points[61].y * h],
                [points[291].x * w, points[291].y * h]
            ]
            aligned_face = self.img_tool.align_face(frame, landmarks_5pt, is_masked=is_masked)
            recognition_face = self.img_tool.enhance_face(aligned_face)

            # 2. æ´»é«”è·¯å¾‘
            
            # 3. æ´»é«”è¨ˆæ¬¡é‚è¼¯ (é€²åº¦ç´¯åŠ åˆ¶)
            if not self.is_locked:
                # åŸ·è¡Œæ¨è«–å–å¾—åŸå§‹åˆ†æ•¸
                raw_score = self.silent_face_analyzer.predict(frame)
                
                # åˆ¤æ–·é€™ä¸€å¹€æ˜¯å¦ã€Œé€šéçœŸäººé–€æª»ã€
                if raw_score >= self.texture_threshold:
                    self.texture_pass_count += 1
                else:
                    # è‹¥æœ‰ä¸€å¹€æ²’éï¼Œé€²åº¦æ­¸é›¶ (ç¢ºä¿é€£çºŒæ€§ï¼Œå¢åŠ å®‰å…¨æ€§)
                    self.texture_pass_count = 0 
                
                # é”åˆ° 5 å¹€å¾Œé–å®š
                if self.texture_pass_count >= self.REQUIRED_PASS_FRAMES:
                    self.texture_pass_count = self.REQUIRED_PASS_FRAMES # å°é ‚
                    self.is_locked = True
            
            # 4. è¨ˆç®— UI é¡¯ç¤ºåˆ†æ•¸ (æ¯å¹€ 20%)
            # å°±ç®—æ²’é–å®šï¼Œä¹Ÿè¦å›å‚³ 0%, 20%, 40%, 60%, 80% çš„é€²åº¦æ„Ÿ
            display_score = self.texture_pass_count / self.REQUIRED_PASS_FRAMES

            return "SUCCESS", {
                "bbox": actual_bbox,
                "is_live": self.is_locked,
                "texture_score": display_score, # å›å‚³ 0.0 ~ 1.0 çš„ç™¾åˆ†æ¯”é€²åº¦
                "face_img": recognition_face if self.is_locked else None 
            }

    def reset_liveness(self):
        self.is_locked = False
        self.texture_pass_count = 0

    def __del__(self):
        """é‡‹æ”¾ MediaPipe è³‡æº"""
        if hasattr(self, 'landmarker'):
            self.landmarker.close()

if __name__ == "__main__":
    # æ¸¬è©¦è…³æœ¬
    cap = cv2.VideoCapture(0)
    detector = FaceDetector()
    
    print("ğŸ¬ é–‹å§‹æ¸¬è©¦ Tasks API åµæ¸¬å™¨ (æŒ‰ 'q' é€€å‡º)...")
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        status, res = detector.process(frame)
        
        if status == "SUCCESS":
            # ç¶ æ¡†ä»£è¡¨çœŸäººé–å®šï¼Œæ©˜æ¡†ä»£è¡¨åˆ¤å®šä¸­
            color = (0, 255, 0) if res['is_live'] else (0, 165, 255)
            # ä½¿ç”¨å¯¦éš›è¨ˆç®—å‡ºçš„ BBox
            cv2.rectangle(frame, (res['bbox'][0], res['bbox'][1]), (res['bbox'][2], res['bbox'][3]), color, 2)
            
            # é¡¯ç¤ºæ´»é«”ç™¾åˆ†æ¯”
            score_text = f"Liveness: {res['texture_score']*100:.1f}%"
            cv2.putText(frame, score_text, (res['bbox'][0], res['bbox'][1]-10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        else:
            cv2.putText(frame, f"Status: {status}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            
        cv2.imshow("EvoFace Detector Test", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break
    
    cap.release()
    cv2.destroyAllWindows()