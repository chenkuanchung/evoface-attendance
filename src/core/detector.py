import cv2
import mediapipe as mp
import numpy as np
import yaml
from src.utils.image_tool import ImagePreprocessor 
from src.core.liveness_engine import SilentFaceAnalyzer

class FaceDetector:
    def __init__(self, config_path="config.yaml"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # åˆå§‹åŒ–æ¨¡å‹èˆ‡å·¥å…·
        self.img_tool = ImagePreprocessor() 
        self.silent_face_analyzer = SilentFaceAnalyzer(config_path=config_path)
        
        # MediaPipe åˆå§‹åŒ– (çœç•¥éƒ¨åˆ†é‡è¤‡ä»£ç¢¼ï¼Œä¿æŒèˆ‡æ‚¨åŸå§‹æª”æ¡ˆçµæ§‹ä¸€è‡´)
        # ... 
        
        self.texture_threshold = self.config.get('thresholds', {}).get('texture_liveness', 0.95)
        self.is_locked = False
        self.texture_pass_count = 0 
        self.REQUIRED_PASS_FRAMES = 10

    def check_mask_status(self, landmarks, frame_h, frame_w):
        """
        ç°¡å–®çš„å£ç½©åˆ¤æ–·é‚è¼¯ï¼šæª¢æŸ¥é¼»å­èˆ‡å˜´è§’é—œéµé»çš„åµæ¸¬ä¿¡å¿ƒæˆ–ä½ç½®
        (å¯¦å‹™ä¸Šå»ºè­°ä½¿ç”¨å°ˆé–€çš„åˆ†é¡å™¨ï¼Œæ­¤è™•ç¤ºç¯„ logic-based åˆ¤æ–·)
        """
        # å¦‚æœé¼»å­ (index 4) æˆ– å˜´å·´é€±é‚Šé»ä½åœ¨ç•«é¢å¤–æˆ–ç•°å¸¸åç§»ï¼Œå‰‡è¦–ç‚ºå£ç½©é®æ“‹
        nose = landmarks[4]
        if nose.y > 0.9 or nose.y < 0.1: # ç¯„ä¾‹åˆ¤æ–·
            return True
        return False

    def process(self, frame):
        h, w, _ = frame.shape
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
        result = self.landmarker.detect(mp_image)
        
        if not result.face_landmarks:
            self.reset_liveness()
            return "NO_FACE", None
            
        points = result.face_landmarks[0]
        
        # 1. æå– 5 å€‹æ ¸å¿ƒå°é½Šé» [å·¦ç³, å³ç³, é¼»å°–, å·¦å˜´è§’, å³å˜´è§’]
        # MediaPipe ç´¢å¼•ï¼šå·¦çœ¼(468), å³çœ¼(473), é¼»å°–(4), å·¦å˜´è§’(61), å³å˜´è§’(291)
        landmarks_5pt = [
            [points[468].x * w, points[468].y * h],
            [points[473].x * w, points[473].y * h],
            [points[4].x * w, points[4].y * h],
            [points[61].x * w, points[61].y * h],
            [points[291].x * w, points[291].y * h]
        ]
        
        # 2. åˆ¤æ–·å£ç½©ç‹€æ…‹
        is_masked = self.check_mask_status(points, h, w)

        if not self.is_locked:
            # 3. åŸ·è¡Œä»¿å°„è®Šæ›èˆ‡å½±åƒå¼·åŒ– (ç¬¬ä¸€æ­¥æ”¹å¯«é‡é»)
            aligned_face = self.img_tool.align_face(frame, landmarks_5pt, is_masked=is_masked)
            processed_face = self.img_tool.enhance_face(aligned_face)
            
            # 4. æ´»é«”æª¢æ¸¬ (ä½¿ç”¨è™•ç†éçš„æ¨™æº–å½±åƒ)
            avg_brightness = self.img_tool.get_brightness(processed_face)
            current_threshold = self.texture_threshold
            if avg_brightness < 70: current_threshold -= 0.05

            texture_score = self.silent_face_analyzer.predict(processed_face)
            
            if texture_score >= current_threshold:
                self.texture_pass_count += 1
            else:
                self.texture_pass_count = 0 
            
            if self.texture_pass_count >= self.REQUIRED_PASS_FRAMES:
                self.is_locked = True
        
        # ... å›å‚³é‚è¼¯ [cite: 36]
        return "SUCCESS", {
            "bbox": [0,0,0,0], # ç°¡åŒ–
            "is_live": self.is_locked,
            "face_img": processed_face if self.is_locked else None # å‚³éçµ¦ recognizer
        }

    def reset_liveness(self):
        self.is_locked = False
        self.texture_pass_count = 0

    def __del__(self):
        if hasattr(self, 'landmarker'):
            self.landmarker.close()

if __name__ == "__main__":
    # æ¸¬è©¦è…³æœ¬
    cap = cv2.VideoCapture(0)
    detector = FaceDetector()
    
    print("ğŸ¬ é–‹å§‹æ¸¬è©¦ Tasks API åµæ¸¬å™¨ (æŒ‰ 'q' é€€å‡º)...")
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        status, res = detector.process(frame)
        
        if status == "SUCCESS":
            # ç¶ æ¡†ä»£è¡¨çœŸäººé–å®šï¼Œæ©˜æ¡†ä»£è¡¨åˆ¤å®šä¸­
            color = (0, 255, 0) if res['is_live'] else (0, 165, 255)
            cv2.rectangle(frame, (res['bbox'][0], res['bbox'][1]), (res['bbox'][2], res['bbox'][3]), color, 2)
            cv2.putText(frame, f"Liveness: {res['liveness_percent']}%", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        else:
            cv2.putText(frame, f"Status: {status}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            
        cv2.imshow("MediaPipe Tasks Detector", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break
    
    cap.release()
    cv2.destroyAllWindows()